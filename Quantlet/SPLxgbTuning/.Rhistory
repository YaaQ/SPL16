??microbenchmark
all.equal(PP, PP2)
identical(PP, PP2)
head(PP)
head(PP1)
str(PP)
str(PP1)
str(PP2)
?repeat
?lapply
compare = function(f) {
system.time(replicate(n = 100, expr = f))
}
compare(solve(spbigIn - kronecker(spbigF, spbigF), spvbigQ))
compare(solve(as(spbigIn - kronecker(spbigF, spbigF), 'triangularMatrix'), spvbigQ), spvbigQ))
compare(solve(as(spbigIn - kronecker(spbigF, spbigF), 'triangularMatrix'), spvbigQ), spvbigQ)
compare(solve(as(spbigIn - kronecker(spbigF, spbigF), 'triangularMatrix'), spvbigQ))
compare(solve(spbigIn - kronecker(spbigF, spbigF), spvbigQ))
compare(solve(as(spbigIn - kronecker(spbigF, spbigF), 'triangularMatrix'), spvbigQ))
compare = function(f) {
system.time(replicate(n = 1000, expr = f))
}
compare(solve(spbigIn - kronecker(spbigF, spbigF), spvbigQ))
compare(solve(as(spbigIn - kronecker(spbigF, spbigF), 'triangularMatrix'), spvbigQ))
replicate(1000, solve(spbigIn - kronecker(spbigF, spbigF), spvbigQ))
compare = function(x) {
system.time(replicate(n = 1000, expr = solve(x, spvbigQ)))
}
compare(spbigIn - kronecker(spbigF, spbigF))
compare(as(spbigIn - kronecker(spbigF, spbigF), 'triangularMatrix'))
compare(spbigIn - kronecker(spbigF, spbigF))
compare(as(spbigIn - kronecker(spbigF, spbigF), 'triangularMatrix'))
aa = matrix(rnorm(2500), ncol = 50)
AA = Matrix(aa)
system.time(replicate(100, aa %*% aa))
system.time(replicate(100, function(x = aa) x %*% x))
system.time(replicate(1000, function(x = aa) x %*% x))
system.time(aa %*% aa)
rr = 500
aa = matrix(rnorm(rr^2), ncol = rr)
AA = Matrix(aa)
system.time(replicate(100, function(x = aa) x %*% x))
system.time(aa %*% aa)
system.time(AA %*% AA)
system.time(aa %*% aa)
system.time(AA %*% AA)
system.time(aa %*% aa)
system.time(AA %*% AA)
rr = 500
aa = matrix(rnorm(rr^2), ncol = rr)
AA = Matrix(aa)
system.time(aa %*% aa)
system.time(AA %*% AA)
rr = 500
aa = matrix(rnorm(rr^2), ncol = rr)
AA = Matrix(aa)
system.time(aa %*% aa)
system.time(AA %*% AA)
system.time(AA %*% aa)
system.time(aa %*% aa)
system.time(AA %*% aa)
system.time(aa %*% aa)
system.time(AA %*% aa)
library(h2o)
load('basic_processing.RData')
setwd('F:/PHD/IRTG/courses/SPL/Quantlet/random_forest_turning')
load('basic_processing.RData')
h2o.init(
nthreads=-1,            ## -1: use all available threads (use all cores)
max_mem_size = "2G")    ## specify the memory size for the H2O cloud
h2o.removeAll() # Clean slate - just in case the cluster was already
train <- basic_data$train
test <- basic_data$test
# specify repetions and number of folds
repetitions <- 2
k_folds <- 5
train_h2o <- as.h2o(train)
# sepecify columns of inputs and labels
col_label <- which(colnames(train) == "y")
col_input <- which(colnames(train) != "y")
rfGrid <- list(mtries = seq(10,30,5),
ntrees = 500,
max_depth = seq(5,25,5),
sample_rate = seq(0.6,0.8,0.2),
stopping_metric = "MSE",
stopping_rounds = 20
)
# draw new seeds in order to run a different cv split each repetition
seeds <- sample(1:1000,repetitions)
rfFit = list()
tuning_results = list()
for(t in 1:repetitions){
#tune random forest with h2o
rfFit[[t]] <- h2o.grid("randomForest",
grid_id = "gridSearch",
x = col_input,
y = col_label,
training_frame = train_h2o,
hyper_params = rfGrid,
nfolds = k_folds,
is_supervised = TRUE,
seed = seeds[1]
)
# get tuning results and save them as csv
tuning_results[[t]] <- h2o.getGrid(grid_id = "gridSearch", sort_by = "rmse")
# write.csv(tuning_results@summary_table,file = paste(result_path,".csv", sep="_"))
}
?h2o.init
h2o.shutdown(prompt = TRUE)
model_ids <- rfFit[[1]]@model_ids
model_ids[[1]]
models <- lapply(model_ids, function(id) { h2o.getModel(id)})
h2o.init(
nthreads=-1,            ## -1: use all available threads (use all cores)
max_mem_size = "2G")    ## specify the memory size for the H2O cloud
models <- lapply(model_ids, function(id) { h2o.getModel(id)})
models <- lapply(model_ids, function(id) { h2o.getModel(id)})
aa = turning_results@summary_table
aa = turning_results[[1]]@summary_table
aa = tuning_results[[1]]@summary_table
View(aa)
plot(aa$rmse)
par(mfrow = c(1, 2))
lapply(tuning_results, function(x) {
aa = x@summary_table
plot(aa$rmse)
})
lapply(tuning_results, function(x) {
aa = x@summary_table
plot(aa$rmse, main = 'RMSE of different parameters', xlabel = NULL, ylabel = NULL)
})
seeds
lapply(tuning_results, function(x) {
aa = x@summary_table
plot(aa$rmse, main = 'RMSE of different parameters', xlabel = '', ylabel = '')
})
warnings()
?plot
lapply(tuning_results, function(x) {
aa = x@summary_table
plot(aa$rmse, main = 'RMSE of different parameters', xlab = '', ylab = '')
})
?mapply
par(mfrow = c(1, 2))
plotRMSE = function(x, seed) {
aa = x@summary_table
plot(aa$rmse, main = paste0('RMSE when seed = ', seed), xlab = '', ylab = '', pch = 20)
}
mapply(plotRMSE, tuning_results, seeds)
plotRMSE = function(x, seed) {
aa = x@summary_table
index = seq_along(aa)
min_aa = min(aa)
index_min = index[aa = min(aa)][1]
plot(aa$rmse, main = paste0('RMSE when seed = ', seed), xlab = '', ylab = '', pch = 20)
points(index_min, min_aa, pch = 21, col = 'red')
}
mapply(plotRMSE, tuning_results, seeds)
plotRMSE = function(x, seed) {
aa = x@summary_table$rmse
index = seq_along(aa)
min_aa = min(aa)
index_min = index[aa = min(aa)][1]
plot(aa, main = paste0('RMSE when seed = ', seed), xlab = '', ylab = '', pch = 20)
points(index_min, min_aa, pch = 21, col = 'red')
}
mapply(plotRMSE, tuning_results, seeds)
plotRMSE = function(x, seed) {
aa = x@summary_table$rmse
index = seq_along(aa)
min_aa = min(aa)
index_min = index[aa = min(aa)][1]
plot(aa, main = paste0('RMSE when seed = ', seed), xlab = '', ylab = '')
points(index_min, min_aa, pch = 21, col = 'red')
}
mapply(plotRMSE, tuning_results, seeds)
?points
plotRMSE = function(x, seed) {
aa = x@summary_table$rmse
index = seq_along(aa)
min_aa = min(aa)
index_min = index[aa = min(aa)][1]
plot(index, aa, main = paste0('RMSE when seed = ', seed), xlab = '', ylab = '')
points(index_min, min_aa, pch = 21, col = 'red')
}
mapply(plotRMSE, tuning_results, seeds)
points(1, 30000, col = 'red')
plotRMSE = function(x, seed) {
aa = x@summary_table$rmse
index = seq_along(aa)
min_aa = min(aa)
index_min = index[aa == min(aa)][1]
plot(index, aa, main = paste0('RMSE when seed = ', seed), xlab = '', ylab = '')
points(index_min, min_aa, pch = 21, col = 'red')
}
mapply(plotRMSE, tuning_results, seeds)
plotRMSE = function(x, seed) {
aa = x@summary_table$rmse
index = seq_along(aa)
min_aa = min(aa)
index_min = index[aa == min(aa)][1]
plot(index, aa, main = paste0('RMSE when seed = ', seed), xlab = '', ylab = '', pch = 20, col = 'grey')
points(index_min, min_aa, pch = 20, col = 'red')
}
mapply(plotRMSE, tuning_results, seeds)
plotRMSE = function(x, seed) {
aa = x@summary_table$rmse
index = seq_along(aa)
min_aa = min(aa)
index_min = index[aa == min(aa)][1]
plot(index, aa, main = paste0('RMSE when seed = ', seed), xlab = '', ylab = '', pch = 20, col = 'grey0')
points(index_min, min_aa, pch = 20, col = 'red')
}
mapply(plotRMSE, tuning_results, seeds)
plotRMSE = function(x, seed) {
aa = x@summary_table$rmse
index = seq_along(aa)
min_aa = min(aa)
index_min = index[aa == min(aa)][1]
plot(index, aa, main = paste0('RMSE when seed = ', seed), xlab = '', ylab = '', pch = 20, col = 'grey10')
points(index_min, min_aa, pch = 20, col = 'red')
}
mapply(plotRMSE, tuning_results, seeds)
plotRMSE = function(x, seed) {
aa = x@summary_table$rmse
index = seq_along(aa)
min_aa = min(aa)
index_min = index[aa == min(aa)][1]
plot(index, aa, main = paste0('RMSE when seed = ', seed), xlab = '', ylab = '', pch = 20, col = 'grey50')
points(index_min, min_aa, pch = 20, col = 'red')
}
mapply(plotRMSE, tuning_results, seeds)
head(aa)
rm(aa)
save.image("F:/PHD/IRTG/courses/SPL/Quantlet/random_forest_turning/random_forest_tuning.RData")
setwd('F:/PHD/IRTG/courses/SPL/Quantlet/svm_tuning')
rm(list = ls())
graphics.off()
library(caret)
load('basic_processing.RData')
train <- basic_data$train
y <- train$y
train$y <- NULL
# set cv parameter
t <- 10 # repetition on inner loop (here caret does it)
k <- 5 # folds on the inner cv loop
# create Grid for GridSearch to tune hyperparameter
svmLinearGrid <-  expand.grid(C = c(0.001,0.01,0.1,1))
svmGaussianGrid <- expand.grid(C = c(0.001,0.01,0.1,1), sigma = c(0.001,0.01,0.1,1))
# determine evaluation method of the inner cv loop
ctrl <- trainControl(method="repeatedcv",
number=t,
repeats=k,
verboseIter=FALSE
)
svmLinearFit <- train(x = train,
y = y,
method = 'svmLinear',  # method
trControl = ctrl,  # evaluatio method (repeated CV)
tuneGrid = svmLinearGrid, # grid
metric = "RMSE",  # error metric
maximize = FALSE
)
plot(svmLinearFit)
plot(svmLinearFit, main = 'SVM fit')
svmGaussianFit <- train(x = train,
y = y,
method = 'svmRadial',  # method
trControl = ctrl,  # evaluatio method (repeated CV)
tuneGrid = svmGaussianGrid, # grid
metric = "RMSE",  # error metric
maximize = FALSE
)
plot(svmGaussianFit)
plot(svmLinearFit, main = 'SVM fit with linear kernel')
plot(svmGaussianFit, main = 'SVM fit with Gaussian kernel')
save.image("F:/PHD/IRTG/courses/SPL/Quantlet/svm_tuning/svm_t.RData")
setwd('F:/PHD/IRTG/courses/SPL/Quantlet/xgb_tuning')
rm(list = ls())
graphics.off()
library(caret)
library(xgboost)
library(Matrix)
load('basic_processing.RData')
train <- basic_data$train
test <-  basic_data$test
X_com <- rbind(train,test)
train <- basic_data$train
test <-  basic_data$test
y <- train$y
train$y <- NULL
X_com <- rbind(train,test)
repetitions <- 5  # repetitions of cv
k_folds <- 5   # folds in the cv loop
# create Grid for GridSearch to tune hyperparameter
# Tree specific Parameters: maxnodes: longest path of a single tree (decreased performance)
#                           colsample_bytree: variable considered at each split
#                           subsample: size of the bagging bootstrap sample
nrounds_fixed <- 1000 # number of trees: no need for tuning since early.stopping is possible
eta_fixed <- 0.025 # learning rate (fixed for now)
treeSpecificGrid <-  expand.grid(max_depth = seq(10,16,2),
gamma = seq(0,6,2), # gamma seems to be not be crucial (we do not tune it)
subsample = seq(0.4,0.8,0.2),
colsample_bytree = seq(0.6,1,0.2)
)
#
result_path <- "output/xgb_basic"
########## perform repeated nested cv
# set cv parameter
repetitions <- 5  # repetitions of cv
k_folds <- 5   # folds in the cv loop
# create Grid for GridSearch to tune hyperparameter
# Tree specific Parameters: maxnodes: longest path of a single tree (decreased performance)
#                           colsample_bytree: variable considered at each split
#                           subsample: size of the bagging bootstrap sample
nrounds_fixed <- 1000 # number of trees: no need for tuning since early.stopping is possible
eta_fixed <- 0.025 # learning rate (fixed for now)
treeSpecificGrid <-  expand.grid(max_depth = seq(10,16,2),
gamma = seq(0,6,2), # gamma seems to be not be crucial (we do not tune it)
subsample = seq(0.4,0.8,0.2),
colsample_bytree = seq(0.6,1,0.2)
)
# samplesize could be inspected as well
numOfParameter <- ncol(treeSpecificGrid)
# create a matrix to with the GridSearch parameters and their RMSE
parameter_names <- c("max_depth",
"gamma",
"subsample",
"colsample_bytree"
)
# set up empty matrices to be filled with rmse and best_paramer (here only lambda)
### start nested repeated nested cv loop
## Repetition outer loop
# create empty vector/matrix to save best results
parameters <- matrix(0, nrow = nrow(treeSpecificGrid), ncol = numOfParameter + 1)
colnames(parameters) <- c("rmse",parameter_names)
result_list <- lapply(seq_len(repetitions), function(X) parameters)
# start repetition loop
for(t in 1:repetitions){
# draw random integers for the k-folds
folds <- sample(rep(1:k_folds, length.out = nrow(train)))
# create empty vector/matrix to save best results
tuning_results <- cbind(rep(0,nrow(treeSpecificGrid)),treeSpecificGrid)
colnames(tuning_results) <- c("rmse",parameter_names)
# start crossvalidation loop
for(k in 1:k_folds){
# split into training and validation set
indexValidation <- which(folds ==k)
training <- train[-indexValidation,]
y_training <- y[-indexValidation]
validation <- train[indexValidation,]
y_validation <- y[indexValidation]
# convert for data into a format xgb.train can handle
dtrain <- xgb.DMatrix(data = as.matrix(training), label=y_training)
dvalidation <- xgb.DMatrix(data = as.matrix(validation), label=y_validation)
watchlist <- list(eval = dvalidation, train = dtrain)
# start GridSearch loop
for(i in 1:nrow(treeSpecificGrid)){
# determine arbitrary xgboost parameters in a list
xgb_paramters = list(
eta = eta_fixed,                                            # learning rate
max.depth = treeSpecificGrid$max_depth[i],                  # max nodes of a tree
gamma = treeSpecificGrid$gamma[i],                          # minimal improvement per iteration
colsample_bytree = treeSpecificGrid$colsample_bytree[i],    # fraction of variable to consider per tree (similar to mtry in rf)
subsample = treeSpecificGrid$subsample[i],                  # fraction of the whole sample that the bootstrap sample should consist of
eval_metric = "rmse",                                       # error metric
maximize = FALSE
)
# fit the xgboost
xgbFit <- xgb.train(params = xgb_paramters,  # list of parameter previously specified
data =  dtrain,
booster = "gbtree",
nround = nrounds_fixed,    #number of trees (set accordingly to tune_nrounds function)
verbose = 1,
early.stop.round = 50,
objective = "reg:linear",
watchlist = watchlist
)
# predict SalePrice
yhat <- predict(xgbFit, newdata = dvalidation)
# fill the first column of this matrix with the rmse results (of the log outputs)
validation_error <- rmse_log(y_validation, yhat)
tuning_results[i,1] <- validation_error
# save all training results as csv file (fold_k_reptetion_t)
write.csv(tuning_results, file = paste(result_path,t,k,".csv", sep="_"))
}#end GridSearch
#rmse_temp[k_2,k_1] <- best_results$rmse[1] # best rmse
}#end inner cv
# fill result list with the best parameter
result_list[[t]] <- tuning_results
}#end repetitions
# print result list
source("utils/performanceMetrics.R")  # to get performance metrics
source('performanceMetrics.R")  # to get performance metrics
# get preprocessed data
train <- basic_data$train
test <-  basic_data$test
y <- train$y
train$y <- NULL
X_com <- rbind(train,test)
# save result path (change according to experiment here: input date is from quick preprocessing function)
result_path <- "output/xgb_basic"
########## perform repeated nested cv
# set cv parameter
repetitions <- 5  # repetitions of cv
k_folds <- 5   # folds in the cv loop
# create Grid for GridSearch to tune hyperparameter
# Tree specific Parameters: maxnodes: longest path of a single tree (decreased performance)
#                           colsample_bytree: variable considered at each split
#                           subsample: size of the bagging bootstrap sample
nrounds_fixed <- 1000 # number of trees: no need for tuning since early.stopping is possible
eta_fixed <- 0.025 # learning rate (fixed for now)
treeSpecificGrid <-  expand.grid(max_depth = seq(10,16,2),
gamma = seq(0,6,2), # gamma seems to be not be crucial (we do not tune it)
subsample = seq(0.4,0.8,0.2),
colsample_bytree = seq(0.6,1,0.2)
)
source('performanceMetrics.R")
source('performanceMetrics.R')  # to get performance metrics
train <- basic_data$train
test <-  basic_data$test
y <- train$y
train$y <- NULL
X_com <- rbind(train,test)
# save result path (change according to experiment here: input date is from quick preprocessing function)
result_path <- "output/xgb_basic"
########## perform repeated nested cv
# set cv parameter
repetitions <- 5  # repetitions of cv
k_folds <- 5   # folds in the cv loop
# create Grid for GridSearch to tune hyperparameter
# Tree specific Parameters: maxnodes: longest path of a single tree (decreased performance)
#                           colsample_bytree: variable considered at each split
#                           subsample: size of the bagging bootstrap sample
nrounds_fixed <- 1000 # number of trees: no need for tuning since early.stopping is possible
eta_fixed <- 0.025 # learning rate (fixed for now)
treeSpecificGrid <-  expand.grid(max_depth = seq(10,16,2),
gamma = seq(0,6,2), # gamma seems to be not be crucial (we do not tune it)
subsample = seq(0.4,0.8,0.2),
colsample_bytree = seq(0.6,1,0.2)
)
# samplesize could be inspected as well
numOfParameter <- ncol(treeSpecificGrid)
# create a matrix to with the GridSearch parameters and their RMSE
parameter_names <- c("max_depth",
"gamma",
"subsample",
"colsample_bytree"
)
# set up empty matrices to be filled with rmse and best_paramer (here only lambda)
### start nested repeated nested cv loop
## Repetition outer loop
# create empty vector/matrix to save best results
parameters <- matrix(0, nrow = nrow(treeSpecificGrid), ncol = numOfParameter + 1)
colnames(parameters) <- c("rmse",parameter_names)
result_list <- lapply(seq_len(repetitions), function(X) parameters)
# start repetition loop
for(t in 1:repetitions){
# draw random integers for the k-folds
folds <- sample(rep(1:k_folds, length.out = nrow(train)))
# create empty vector/matrix to save best results
tuning_results <- cbind(rep(0,nrow(treeSpecificGrid)),treeSpecificGrid)
colnames(tuning_results) <- c("rmse",parameter_names)
# start crossvalidation loop
for(k in 1:k_folds){
# split into training and validation set
indexValidation <- which(folds ==k)
training <- train[-indexValidation,]
y_training <- y[-indexValidation]
validation <- train[indexValidation,]
y_validation <- y[indexValidation]
# convert for data into a format xgb.train can handle
dtrain <- xgb.DMatrix(data = as.matrix(training), label=y_training)
dvalidation <- xgb.DMatrix(data = as.matrix(validation), label=y_validation)
watchlist <- list(eval = dvalidation, train = dtrain)
# start GridSearch loop
for(i in 1:nrow(treeSpecificGrid)){
# determine arbitrary xgboost parameters in a list
xgb_paramters = list(
eta = eta_fixed,                                            # learning rate
max.depth = treeSpecificGrid$max_depth[i],                  # max nodes of a tree
gamma = treeSpecificGrid$gamma[i],                          # minimal improvement per iteration
colsample_bytree = treeSpecificGrid$colsample_bytree[i],    # fraction of variable to consider per tree (similar to mtry in rf)
subsample = treeSpecificGrid$subsample[i],                  # fraction of the whole sample that the bootstrap sample should consist of
eval_metric = "rmse",                                       # error metric
maximize = FALSE
)
# fit the xgboost
xgbFit <- xgb.train(params = xgb_paramters,  # list of parameter previously specified
data =  dtrain,
booster = "gbtree",
nround = nrounds_fixed,    #number of trees (set accordingly to tune_nrounds function)
verbose = 1,
early.stop.round = 50,
objective = "reg:linear",
watchlist = watchlist
)
# predict SalePrice
yhat <- predict(xgbFit, newdata = dvalidation)
# fill the first column of this matrix with the rmse results (of the log outputs)
validation_error <- rmse_log(y_validation, yhat)
tuning_results[i,1] <- validation_error
# save all training results as csv file (fold_k_reptetion_t)
write.csv(tuning_results, file = paste(result_path,t,k,".csv", sep="_"))
}#end GridSearch
#rmse_temp[k_2,k_1] <- best_results$rmse[1] # best rmse
}#end inner cv
# fill result list with the best parameter
result_list[[t]] <- tuning_results
}#end repetitions
# print result list
print(result_list)
